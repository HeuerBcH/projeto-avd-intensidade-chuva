{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados (EDA)\n",
    "## Dados Meteorológicos do INMET - Pernambuco\n",
    "\n",
    "**Objetivo:** Realizar análise exploratória dos dados meteorológicos coletados das estações automáticas do INMET no estado de Pernambuco.\n",
    "\n",
    "**Foco:** Entender a distribuição dos dados, identificar problemas e preparar para tratamento e modelagem.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importação de Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package.split('-')[0].split('[')[0])\n",
    "    except ImportError:\n",
    "        print(f\"Instalando {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", package])\n",
    "\n",
    "dependencies = [\n",
    "    'pandas', 'numpy', 'matplotlib', 'seaborn', 'sqlalchemy', 'psycopg2-binary'\n",
    "]\n",
    "\n",
    "for dep in dependencies:\n",
    "    install_if_missing(dep)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuração de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conexão com PostgreSQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração de conexão definida!\n"
     ]
    }
   ],
   "source": [
    "# Configurações de conexão com PostgreSQL\n",
    "DB_CONFIG = {\n",
    "    'host': 'postgres',\n",
    "    'port': 5432,\n",
    "    'database': 'inmet_db',\n",
    "    'user': 'inmet_user',\n",
    "    'password': 'inmet_password'\n",
    "}\n",
    "\n",
    "print(\"Configuração de conexão definida!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregamento dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n",
      "Dados carregados: 0 registros\n",
      "\n",
      "ATENÇÃO: Nenhum dado encontrado no banco!\n",
      "\n",
      "Para carregar dados, execute:\n",
      "1. Coloque arquivos CSV em: fastapi/app/data/raw/\n",
      "2. Execute: curl -X POST http://localhost:8000/ingest\n",
      "3. Execute: curl -X POST http://localhost:8000/load-to-db\n",
      "\n",
      "Ou use a interface do FastAPI em: http://localhost:8000/docs\n"
     ]
    }
   ],
   "source": [
    "# Query para carregar dados meteorológicos\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    dm.*,\n",
    "    e.nome as nome_estacao,\n",
    "    e.uf,\n",
    "    e.latitude,\n",
    "    e.longitude\n",
    "FROM dados_meteorologicos dm\n",
    "JOIN estacoes e ON dm.codigo_wmo = e.codigo_wmo\n",
    "ORDER BY dm.timestamp_utc\n",
    "\"\"\"\n",
    "\n",
    "# Lê dados usando conexão direta com psycopg2 (evita problemas de encoding)\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_CONFIG['host'],\n",
    "        port=DB_CONFIG['port'],\n",
    "        database=DB_CONFIG['database'],\n",
    "        user=DB_CONFIG['user'],\n",
    "        password=DB_CONFIG['password']\n",
    "    )\n",
    "    conn.set_client_encoding('UTF8')\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    # Converte timestamp\n",
    "    df['timestamp_utc'] = pd.to_datetime(df['timestamp_utc'])\n",
    "    \n",
    "    print(\"Dados carregados com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar dados: {e}\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "print(f\"Dados carregados: {len(df):,} registros\")\n",
    "\n",
    "# Verifica se há dados antes de processar\n",
    "if len(df) == 0:\n",
    "    print(\"\\nATENÇÃO: Nenhum dado encontrado no banco!\")\n",
    "    print(\"\\nPara carregar dados, execute:\")\n",
    "    print(\"1. Coloque arquivos CSV em: fastapi/app/data/raw/\")\n",
    "    print(\"2. Execute: curl -X POST http://localhost:8000/ingest\")\n",
    "    print(\"3. Execute: curl -X POST http://localhost:8000/load-to-db\")\n",
    "    print(\"\\nOu use a interface do FastAPI em: http://localhost:8000/docs\")\n",
    "else:\n",
    "    print(f\"Período: {df['timestamp_utc'].min()} até {df['timestamp_utc'].max()}\")\n",
    "    print(f\"Estações: {df['codigo_wmo'].nunique()} estações únicas\")\n",
    "    print(\"\\nPrimeiras linhas:\")\n",
    "    display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Informações Gerais do Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhum dado disponível para análise!\n"
     ]
    }
   ],
   "source": [
    "if len(df) > 0:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"INFORMAÇÕES GERAIS DO DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nDimensões: {df.shape[0]:,} linhas x {df.shape[1]} colunas\")\n",
    "    print(f\"Número de estações: {df['codigo_wmo'].nunique()}\")\n",
    "    \n",
    "    if pd.notna(df['timestamp_utc'].min()) and pd.notna(df['timestamp_utc'].max()):\n",
    "        print(f\"Período: {df['timestamp_utc'].min()} até {df['timestamp_utc'].max()}\")\n",
    "        total_dias = (df['timestamp_utc'].max() - df['timestamp_utc'].min()).days\n",
    "        print(f\"Total de dias: {total_dias} dias\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ESTAÇÕES METEOROLÓGICAS\")\n",
    "    print(\"=\" * 60)\n",
    "    estacoes = df.groupby('codigo_wmo').agg({\n",
    "        'nome_estacao': 'first',\n",
    "        'uf': 'first',\n",
    "        'timestamp_utc': ['min', 'max', 'count']\n",
    "    }).round(2)\n",
    "    estacoes.columns = ['Estação', 'UF', 'Data Início', 'Data Fim', 'Total Registros']\n",
    "    display(estacoes)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TIPOS DE DADOS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(df.dtypes)\n",
    "else:\n",
    "    print(\"Nenhum dado disponível para análise!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise de Valores Faltantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhum dado disponível para análise!\n"
     ]
    }
   ],
   "source": [
    "if len(df) > 0:\n",
    "    # Análise de valores faltantes\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Variável': missing.index,\n",
    "        'Valores Faltantes': missing.values,\n",
    "        'Percentual (%)': missing_pct.values\n",
    "    }).sort_values('Valores Faltantes', ascending=False)\n",
    "    \n",
    "    missing_df = missing_df[missing_df['Valores Faltantes'] > 0]\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"VALORES FALTANTES POR VARIÁVEL\")\n",
    "    print(\"=\" * 60)\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Visualização\n",
    "    if len(missing_df) > 0:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(missing_df['Variável'], missing_df['Percentual (%)'])\n",
    "        plt.xlabel('Percentual de Valores Faltantes (%)', fontsize=12, fontweight='bold')\n",
    "        plt.title('Análise de Valores Faltantes por Variável', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nNenhum valor faltante encontrado!\")\n",
    "else:\n",
    "    print(\"Nenhum dado disponível para análise!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Estatísticas Descritivas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhum dado disponível para análise!\n"
     ]
    }
   ],
   "source": [
    "if len(df) > 0:\n",
    "    # Seleciona variáveis numéricas principais\n",
    "    vars_numericas = [\n",
    "        'precipitacao_mm', 'pressao_estacao_mb', 'temperatura_ar_c',\n",
    "        'umidade_rel_horaria_pct', 'vento_velocidade_ms', 'radiacao_global_kjm2'\n",
    "    ]\n",
    "    \n",
    "    vars_existentes = [v for v in vars_numericas if v in df.columns]\n",
    "    \n",
    "    if vars_existentes:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"ESTATÍSTICAS DESCRITIVAS\")\n",
    "        print(\"=\" * 60)\n",
    "        display(df[vars_existentes].describe())\n",
    "        \n",
    "        # Visualização de distribuições\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, var in enumerate(vars_existentes[:6]):\n",
    "            if i < len(axes):\n",
    "                df[var].hist(bins=50, ax=axes[i], edgecolor='black', alpha=0.7)\n",
    "                axes[i].set_title(f'Distribuição de {var}', fontweight='bold')\n",
    "                axes[i].set_xlabel(var)\n",
    "                axes[i].set_ylabel('Frequência')\n",
    "                axes[i].grid(alpha=0.3)\n",
    "        \n",
    "        # Remove eixos vazios\n",
    "        for i in range(len(vars_existentes), len(axes)):\n",
    "            fig.delaxes(axes[i])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Nenhuma variável numérica encontrada!\")\n",
    "else:\n",
    "    print(\"Nenhum dado disponível para análise!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análise de Precipitação (Variável Principal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de precipitação não disponíveis!\n"
     ]
    }
   ],
   "source": [
    "if len(df) > 0 and 'precipitacao_mm' in df.columns:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ANÁLISE DE PRECIPITAÇÃO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Estatísticas\n",
    "    print(f\"\\nEstatísticas de Precipitação:\")\n",
    "    print(f\"  Média: {df['precipitacao_mm'].mean():.2f} mm\")\n",
    "    print(f\"  Mediana: {df['precipitacao_mm'].median():.2f} mm\")\n",
    "    print(f\"  Máximo: {df['precipitacao_mm'].max():.2f} mm\")\n",
    "    print(f\"  Mínimo: {df['precipitacao_mm'].min():.2f} mm\")\n",
    "    print(f\"  Desvio Padrão: {df['precipitacao_mm'].std():.2f} mm\")\n",
    "    \n",
    "    # Valores nulos\n",
    "    nulos = df['precipitacao_mm'].isnull().sum()\n",
    "    print(f\"\\n  Valores nulos: {nulos:,} ({nulos/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # Visualização\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "    # Histograma\n",
    "    df['precipitacao_mm'].hist(bins=100, ax=axes[0], edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_title('Distribuição de Precipitação', fontweight='bold', fontsize=12)\n",
    "    axes[0].set_xlabel('Precipitação (mm)')\n",
    "    axes[0].set_ylabel('Frequência')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Box plot\n",
    "    df['precipitacao_mm'].plot(kind='box', ax=axes[1], vert=True)\n",
    "    axes[1].set_title('Box Plot de Precipitação', fontweight='bold', fontsize=12)\n",
    "    axes[1].set_ylabel('Precipitação (mm)')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Dados de precipitação não disponíveis!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análise Temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados temporais não disponíveis!\n"
     ]
    }
   ],
   "source": [
    "if len(df) > 0 and 'timestamp_utc' in df.columns:\n",
    "    # Extrai componentes temporais\n",
    "    df['ano'] = df['timestamp_utc'].dt.year\n",
    "    df['mes'] = df['timestamp_utc'].dt.month\n",
    "    df['dia'] = df['timestamp_utc'].dt.day\n",
    "    df['hora'] = df['timestamp_utc'].dt.hour\n",
    "    \n",
    "    # Agregação mensal de precipitação\n",
    "    if 'precipitacao_mm' in df.columns:\n",
    "        df_mensal = df.groupby(['ano', 'mes']).agg({\n",
    "            'precipitacao_mm': 'sum'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Cria data a partir de ano e mês (corrigido)\n",
    "        df_mensal['data'] = pd.to_datetime({\n",
    "            'year': df_mensal['ano'],\n",
    "            'month': df_mensal['mes'],\n",
    "            'day': 1\n",
    "        })\n",
    "        \n",
    "        # Visualização\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(df_mensal['data'], df_mensal['precipitacao_mm'], marker='o', linewidth=2, markersize=4)\n",
    "        plt.title('Precipitação Mensal Total', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Data', fontsize=12)\n",
    "        plt.ylabel('Precipitação Total (mm)', fontsize=12)\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nPrecipitação por Mês:\")\n",
    "        display(df_mensal)\n",
    "else:\n",
    "    print(\"Dados temporais não disponíveis!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumo da Análise Exploratória\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESUMO DA ANÁLISE EXPLORATÓRIA\n",
      "================================================================================\n",
      "\n",
      "Nenhum dado disponível!\n",
      "   Execute a ingestão de dados primeiro.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RESUMO DA ANÁLISE EXPLORATÓRIA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(df) > 0:\n",
    "    print(f\"\\nDataset carregado com sucesso!\")\n",
    "    print(f\"   - Total de registros: {len(df):,}\")\n",
    "    print(f\"   - Número de estações: {df['codigo_wmo'].nunique()}\")\n",
    "    print(f\"   - Período: {df['timestamp_utc'].min()} até {df['timestamp_utc'].max()}\")\n",
    "    \n",
    "    print(f\"\\nPróximos passos:\")\n",
    "    print(f\"   1. Executar notebook 02_tratamento_limpeza.ipynb\")\n",
    "    print(f\"   2. Tratar valores faltantes\")\n",
    "    print(f\"   3. Classificar intensidade de chuva\")\n",
    "    print(f\"   4. Preparar dados para modelagem\")\n",
    "else:\n",
    "    print(\"\\nNenhum dado disponível!\")\n",
    "    print(\"   Execute a ingestão de dados primeiro.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
