{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando e atualizando depend√™ncias...\n",
      "Depend√™ncias atualizadas\n",
      "Instalando scikit-learn...\n",
      "Instalando xgboost...\n",
      "Instalando mlflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyopenssl 23.1.1 requires cryptography<41,>=38.0.0, but you have cryptography 46.0.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package.split('-')[0].split('[')[0])\n",
    "    except ImportError:\n",
    "        print(f\"Instalando {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", package])\n",
    "\n",
    "# Atualiza typing_extensions primeiro (resolve problema de compatibilidade com pydantic/mlflow)\n",
    "print(\"Verificando e atualizando depend√™ncias...\")\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"--quiet\", \n",
    "                          \"typing_extensions>=4.8.0\", \"pydantic>=2.0.0\"])\n",
    "    print(\"Depend√™ncias atualizadas\")\n",
    "except:\n",
    "    print(\"Aviso: Algumas depend√™ncias podem precisar de atualiza√ß√£o manual\")\n",
    "\n",
    "dependencies = [\n",
    "    'pandas', 'numpy', 'sqlalchemy', 'psycopg2-binary', 'scikit-learn',\n",
    "    'xgboost', 'mlflow', 'matplotlib', 'seaborn'\n",
    "]\n",
    "\n",
    "for dep in dependencies:\n",
    "    install_if_missing(dep)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# MLFlow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√£o do MLFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 14:27:01 INFO mlflow.tracking.fluent: Experiment with name 'intensidade_chuva_classificacao' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLFlow conectado: http://mlflow:5000\n",
      "‚úÖ Experimento: intensidade_chuva_classificacao\n",
      "‚úÖ S3 (MinIO) configurado para artifacts: http://minio:9000\n",
      "‚úÖ Artifacts ser√£o salvos em: s3://mlflow-artifacts\n"
     ]
    }
   ],
   "source": [
    "# Configura MLFlow tracking\n",
    "# MLFlow est√° rodando no container 'mlflow' na porta 5000\n",
    "import os\n",
    "\n",
    "# ‚ö†Ô∏è IMPORTANTE: Configura√ß√£o S3 (MinIO) para artifact store\n",
    "# Isso permite que os modelos sejam salvos no S3\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'minioadmin'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'minioadmin'\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = 'http://minio:9000'\n",
    "os.environ['AWS_S3_FORCE_PATH_STYLE'] = 'true'\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"http://mlflow:5000\"\n",
    "\n",
    "try:\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment(\"intensidade_chuva_classificacao\")\n",
    "    print(f\"‚úÖ MLFlow conectado: {MLFLOW_TRACKING_URI}\")\n",
    "    print(f\"‚úÖ Experimento: intensidade_chuva_classificacao\")\n",
    "    print(f\"‚úÖ S3 (MinIO) configurado para artifacts: http://minio:9000\")\n",
    "    print(f\"‚úÖ Artifacts ser√£o salvos em: s3://mlflow-artifacts\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao conectar MLFlow: {e}\")\n",
    "    print(\"Continuando sem MLFlow...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conex√£o com PostgreSQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configura√ß√£o de conex√£o definida!\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes de conex√£o\n",
    "DB_CONFIG = {\n",
    "    'host': 'postgres',\n",
    "    'port': 5432,\n",
    "    'database': 'inmet_db',\n",
    "    'user': 'inmet_user',\n",
    "    'password': 'inmet_password'\n",
    "}\n",
    "\n",
    "print(\"Configura√ß√£o de conex√£o definida!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Carregamento dos Dados Tratados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso!\n",
      "Dados carregados: 177,380 registros\n",
      "Per√≠odo: 2024-01-01 00:00:00 at√© 2025-10-31 23:00:00\n",
      "\n",
      "Distribui√ß√£o de classes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intensidade_chuva\n",
       "sem_chuva    170552\n",
       "leve           5945\n",
       "moderada        759\n",
       "forte           124\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (177380, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>codigo_wmo</th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>precipitacao_mm</th>\n",
       "      <th>intensidade_chuva</th>\n",
       "      <th>pressao_estacao_mb</th>\n",
       "      <th>pressao_max_mb</th>\n",
       "      <th>pressao_min_mb</th>\n",
       "      <th>temperatura_ar_c</th>\n",
       "      <th>temperatura_max_c</th>\n",
       "      <th>...</th>\n",
       "      <th>umidade_rel_min_pct</th>\n",
       "      <th>vento_velocidade_ms</th>\n",
       "      <th>vento_direcao_graus</th>\n",
       "      <th>vento_rajada_max_ms</th>\n",
       "      <th>radiacao_global_kjm2</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>hora</th>\n",
       "      <th>dia_semana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16080</td>\n",
       "      <td>A307</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sem_chuva</td>\n",
       "      <td>970.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>26.8</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>2.2</td>\n",
       "      <td>294.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32160</td>\n",
       "      <td>A309</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sem_chuva</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48240</td>\n",
       "      <td>A322</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sem_chuva</td>\n",
       "      <td>922.1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>22.2</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>3.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64320</td>\n",
       "      <td>A328</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sem_chuva</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80400</td>\n",
       "      <td>A329</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sem_chuva</td>\n",
       "      <td>974.2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>28.4</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id codigo_wmo timestamp_utc  precipitacao_mm intensidade_chuva  \\\n",
       "0  16080       A307    2024-01-01              0.0         sem_chuva   \n",
       "1  32160       A309    2024-01-01              0.0         sem_chuva   \n",
       "2  48240       A322    2024-01-01              0.0         sem_chuva   \n",
       "3  64320       A328    2024-01-01              0.0         sem_chuva   \n",
       "4  80400       A329    2024-01-01              0.0         sem_chuva   \n",
       "\n",
       "   pressao_estacao_mb pressao_max_mb pressao_min_mb  temperatura_ar_c  \\\n",
       "0               970.5           None           None              26.8   \n",
       "1                 0.0           None           None               0.0   \n",
       "2               922.1           None           None              22.2   \n",
       "3                 0.0           None           None               0.0   \n",
       "4               974.2           None           None              28.4   \n",
       "\n",
       "  temperatura_max_c  ... umidade_rel_min_pct  vento_velocidade_ms  \\\n",
       "0              None  ...                None                  2.2   \n",
       "1              None  ...                None                  0.0   \n",
       "2              None  ...                None                  3.5   \n",
       "3              None  ...                None                  0.0   \n",
       "4              None  ...                None                  0.0   \n",
       "\n",
       "  vento_direcao_graus vento_rajada_max_ms  radiacao_global_kjm2     ano  mes  \\\n",
       "0               294.0                None                   0.0  2024.0  1.0   \n",
       "1                 0.0                None                   0.0  2024.0  1.0   \n",
       "2                64.0                None                   0.0  2024.0  1.0   \n",
       "3                 0.0                None                   0.0  2024.0  1.0   \n",
       "4               307.0                None                   0.0  2024.0  1.0   \n",
       "\n",
       "   dia  hora  dia_semana  \n",
       "0  1.0   0.0         1.0  \n",
       "1  1.0   0.0         1.0  \n",
       "2  1.0   0.0         1.0  \n",
       "3  1.0   0.0         1.0  \n",
       "4  1.0   0.0         1.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carrega dados tratados (com intensidade_chuva j√° classificada)\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    dm.id,\n",
    "    dm.codigo_wmo,\n",
    "    dm.timestamp_utc,\n",
    "    dm.precipitacao_mm,\n",
    "    dm.intensidade_chuva,\n",
    "    dm.pressao_estacao_mb,\n",
    "    dm.pressao_max_mb,\n",
    "    dm.pressao_min_mb,\n",
    "    dm.temperatura_ar_c,\n",
    "    dm.temperatura_max_c,\n",
    "    dm.temperatura_min_c,\n",
    "    dm.umidade_rel_horaria_pct,\n",
    "    dm.umidade_rel_max_pct,\n",
    "    dm.umidade_rel_min_pct,\n",
    "    dm.vento_velocidade_ms,\n",
    "    dm.vento_direcao_graus,\n",
    "    dm.vento_rajada_max_ms,\n",
    "    dm.radiacao_global_kjm2,\n",
    "    EXTRACT(YEAR FROM dm.timestamp_utc) as ano,\n",
    "    EXTRACT(MONTH FROM dm.timestamp_utc) as mes,\n",
    "    EXTRACT(DAY FROM dm.timestamp_utc) as dia,\n",
    "    EXTRACT(HOUR FROM dm.timestamp_utc) as hora,\n",
    "    EXTRACT(DOW FROM dm.timestamp_utc) as dia_semana\n",
    "FROM dados_meteorologicos dm\n",
    "WHERE dm.intensidade_chuva IS NOT NULL\n",
    "ORDER BY dm.timestamp_utc\n",
    "\"\"\"\n",
    "\n",
    "# L√™ dados usando conex√£o direta com psycopg2 (evita problemas de encoding)\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_CONFIG['host'],\n",
    "        port=DB_CONFIG['port'],\n",
    "        database=DB_CONFIG['database'],\n",
    "        user=DB_CONFIG['user'],\n",
    "        password=DB_CONFIG['password']\n",
    "    )\n",
    "    conn.set_client_encoding('UTF8')\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    df['timestamp_utc'] = pd.to_datetime(df['timestamp_utc'])\n",
    "    print(\"Dados carregados com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar dados: {e}\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "if len(df) == 0:\n",
    "    print(\"\\nATEN√á√ÉO: Nenhum dado encontrado no banco!\")\n",
    "    print(\"\\nExecute primeiro o notebook 02_tratamento_limpeza.ipynb\")\n",
    "else:\n",
    "    print(f\"Dados carregados: {len(df):,} registros\")\n",
    "    print(f\"Per√≠odo: {df['timestamp_utc'].min()} at√© {df['timestamp_utc'].max()}\")\n",
    "    print(f\"\\nDistribui√ß√£o de classes:\")\n",
    "    display(df['intensidade_chuva'].value_counts())\n",
    "    print(f\"\\nShape: {df.shape}\")\n",
    "    display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Preenchidos 195 valores faltantes em precipitacao_mm com 0\n",
      "‚ö†Ô∏è  Preenchidos 95 valores faltantes em pressao_estacao_mb com 0\n",
      "‚ö†Ô∏è  Preenchidos 177,380 valores faltantes em pressao_max_mb com 0\n",
      "‚ö†Ô∏è  Preenchidos 177,380 valores faltantes em pressao_min_mb com 0\n",
      "‚ö†Ô∏è  Preenchidos 96 valores faltantes em temperatura_ar_c com 0\n",
      "‚ö†Ô∏è  Preenchidos 177,380 valores faltantes em temperatura_max_c com 0\n",
      "‚ö†Ô∏è  Preenchidos 177,380 valores faltantes em temperatura_min_c com 0\n",
      "‚ö†Ô∏è  Preenchidos 95 valores faltantes em umidade_rel_horaria_pct com 0\n",
      "‚ö†Ô∏è  Preenchidos 177,380 valores faltantes em umidade_rel_max_pct com 0\n",
      "‚ö†Ô∏è  Preenchidos 177,380 valores faltantes em umidade_rel_min_pct com 0\n",
      "‚ö†Ô∏è  Preenchidos 177,380 valores faltantes em vento_rajada_max_ms com 0\n",
      "\n",
      "‚úÖ Mapeamento de classes:\n",
      "  forte: 0\n",
      "  leve: 1\n",
      "  moderada: 2\n",
      "  sem_chuva: 3\n",
      "\n",
      "‚úÖ Features selecionadas: 19\n",
      "‚úÖ Shape X: (177380, 19)\n",
      "‚úÖ Shape y: (177380,)\n",
      "\n",
      "üìä Distribui√ß√£o de classes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intensidade_chuva\n",
       "sem_chuva    170552\n",
       "leve           5945\n",
       "moderada        759\n",
       "forte           124\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(df) > 0:\n",
    "    # Seleciona features para modelagem\n",
    "    feature_cols = [\n",
    "        'precipitacao_mm',\n",
    "        'pressao_estacao_mb', 'pressao_max_mb', 'pressao_min_mb',\n",
    "        'temperatura_ar_c', 'temperatura_max_c', 'temperatura_min_c',\n",
    "        'umidade_rel_horaria_pct', 'umidade_rel_max_pct', 'umidade_rel_min_pct',\n",
    "        'vento_velocidade_ms', 'vento_direcao_graus', 'vento_rajada_max_ms',\n",
    "        'radiacao_global_kjm2',\n",
    "        'ano', 'mes', 'dia', 'hora', 'dia_semana'\n",
    "    ]\n",
    "    \n",
    "    # Remove colunas que n√£o existem no dataframe\n",
    "    feature_cols = [col for col in feature_cols if col in df.columns]\n",
    "    \n",
    "    # ‚ö†Ô∏è CORRE√á√ÉO: Preenche valores faltantes em vez de remover todas as linhas\n",
    "    # Isso evita que o dataframe fique vazio ap√≥s dropna()\n",
    "    for col in feature_cols:\n",
    "        if df[col].isna().any():\n",
    "            missing_count = df[col].isna().sum()\n",
    "            df[col] = df[col].fillna(0)\n",
    "            if missing_count > 0:\n",
    "                print(f\"‚ö†Ô∏è  Preenchidos {missing_count:,} valores faltantes em {col} com 0\")\n",
    "    \n",
    "    # Prepara X (features) e y (target)\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df['intensidade_chuva'].copy()\n",
    "    \n",
    "    # Codifica vari√°vel target\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    # Mapeia classes para refer√™ncia\n",
    "    class_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    print(\"\\n‚úÖ Mapeamento de classes:\")\n",
    "    for classe, codigo in class_mapping.items():\n",
    "        print(f\"  {classe}: {codigo}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Features selecionadas: {len(feature_cols)}\")\n",
    "    print(f\"‚úÖ Shape X: {X.shape}\")\n",
    "    print(f\"‚úÖ Shape y: {y_encoded.shape}\")\n",
    "    print(f\"\\nüìä Distribui√ß√£o de classes:\")\n",
    "    display(pd.Series(y).value_counts())\n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado dispon√≠vel para modelagem!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divis√£o treino/teste conclu√≠da!\n",
      "Treino: 141,904 amostras\n",
      "Teste: 35,476 amostras\n",
      "\n",
      "Distribui√ß√£o de classes no treino:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        99\n",
       "1      4756\n",
       "2       607\n",
       "3    136442\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribui√ß√£o de classes no teste:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       25\n",
       "1     1189\n",
       "2      152\n",
       "3    34110\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(df) > 0:\n",
    "    # Divide em treino e teste (80/20)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # Normaliza features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(f\"Divis√£o treino/teste conclu√≠da!\")\n",
    "    print(f\"Treino: {X_train.shape[0]:,} amostras\")\n",
    "    print(f\"Teste: {X_test.shape[0]:,} amostras\")\n",
    "    print(f\"\\nDistribui√ß√£o de classes no treino:\")\n",
    "    display(pd.Series(y_train).value_counts().sort_index())\n",
    "    print(f\"\\nDistribui√ß√£o de classes no teste:\")\n",
    "    display(pd.Series(y_test).value_counts().sort_index())\n",
    "else:\n",
    "    print(\"Nenhum dado dispon√≠vel!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fun√ß√£o de Avalia√ß√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun√ß√£o de avalia√ß√£o definida!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Avalia modelo e retorna m√©tricas\"\"\"\n",
    "    # Treina modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # M√©tricas\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'cv_accuracy_mean': cv_mean,\n",
    "        'cv_accuracy_std': cv_std\n",
    "    }\n",
    "    \n",
    "    return model, metrics, y_test_pred\n",
    "\n",
    "print(\"Fun√ß√£o de avalia√ß√£o definida!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Treinamento de Modelos com MLFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 14:27:05 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Treinando RandomForest...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 14:27:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/04 14:27:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: Modelo n√£o foi salvo no MLFlow (m√©tricas foram registradas)\n",
      "   Erro: API request to endpoint /api/2.0/mlflow/logged-models failed with error code 404 != 200. Response bo\n",
      "Accuracy (Treino): 1.0000\n",
      "Accuracy (Teste): 0.9999\n",
      "F1-Score (Teste): 0.9999\n",
      "CV Accuracy: 0.9997 (+/- 0.0001)\n",
      "üèÉ View run RandomForest at: http://mlflow:5000/#/experiments/1/runs/f5ab61c627c94e93bfcd750cbb452725\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n",
      "\n",
      "============================================================\n",
      "Treinando GradientBoosting...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 14:29:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/04 14:29:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aviso: Modelo n√£o foi salvo no MLFlow (m√©tricas foram registradas)\n",
      "   Erro: API request to endpoint /api/2.0/mlflow/logged-models failed with error code 404 != 200. Response bo\n",
      "Accuracy (Treino): 1.0000\n",
      "Accuracy (Teste): 1.0000\n",
      "F1-Score (Teste): 1.0000\n",
      "CV Accuracy: 1.0000 (+/- 0.0000)\n",
      "üèÉ View run GradientBoosting at: http://mlflow:5000/#/experiments/1/runs/6e04e53dde3d40cf870243a76984129d\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n",
      "\n",
      "============================================================\n",
      "Treinando LogisticRegression...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if len(df) > 0:\n",
    "    # Define modelos a testar\n",
    "    models = {\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "    }\n",
    "    \n",
    "    # Tenta adicionar XGBoost se dispon√≠vel\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        models['XGBoost'] = xgb.XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    except ImportError:\n",
    "        print(\"XGBoost n√£o dispon√≠vel, pulando...\")\n",
    "    \n",
    "    # Dicion√°rio para armazenar resultados\n",
    "    results = {}\n",
    "    \n",
    "    # Treina cada modelo\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Treinando {model_name}...\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            with mlflow.start_run(run_name=model_name):\n",
    "                # Treina e avalia\n",
    "                trained_model, metrics, predictions = evaluate_model(\n",
    "                    model, X_train_scaled, X_test_scaled, y_train, y_test, model_name\n",
    "                )\n",
    "                \n",
    "                # Loga par√¢metros\n",
    "                mlflow.log_params(model.get_params())\n",
    "                \n",
    "                # Loga m√©tricas\n",
    "                for metric_name, metric_value in metrics.items():\n",
    "                    if isinstance(metric_value, (int, float)):\n",
    "                        mlflow.log_metric(metric_name, metric_value)\n",
    "                \n",
    "                # Loga modelo (tenta salvar, mas continua mesmo se falhar)\n",
    "                try:\n",
    "                    mlflow.sklearn.log_model(\n",
    "                        sk_model=trained_model, \n",
    "                        artifact_path=\"model\",\n",
    "                        registered_model_name=f\"{model_name}_intensidade_chuva\"\n",
    "                    )\n",
    "                    print(\"Modelo salvo no MLFlow\")\n",
    "                except Exception as model_error:\n",
    "                    # Tenta m√©todo alternativo sem registro\n",
    "                    try:\n",
    "                        mlflow.sklearn.log_model(\n",
    "                            sk_model=trained_model, \n",
    "                            artifact_path=\"model\"\n",
    "                        )\n",
    "                        print(\"Modelo salvo no MLFlow (sem registro)\")\n",
    "                    except:\n",
    "                        print(f\"Aviso: Modelo n√£o foi salvo no MLFlow (m√©tricas foram registradas)\")\n",
    "                        print(f\"   Erro: {str(model_error)[:100]}\")\n",
    "                \n",
    "                # Salva resultados\n",
    "                results[model_name] = {\n",
    "                    'model': trained_model,\n",
    "                    'metrics': metrics,\n",
    "                    'predictions': predictions\n",
    "                }\n",
    "                \n",
    "                print(f\"Accuracy (Treino): {metrics['train_accuracy']:.4f}\")\n",
    "                print(f\"Accuracy (Teste): {metrics['test_accuracy']:.4f}\")\n",
    "                print(f\"F1-Score (Teste): {metrics['test_f1']:.4f}\")\n",
    "                print(f\"CV Accuracy: {metrics['cv_accuracy_mean']:.4f} (+/- {metrics['cv_accuracy_std']:.4f})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao treinar {model_name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Treinamento conclu√≠do!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Compara modelos\n",
    "    if results:\n",
    "        print(\"\\nCompara√ß√£o de Modelos:\")\n",
    "        comparison_df = pd.DataFrame([r['metrics'] for r in results.values()])\n",
    "        display(comparison_df[['model_name', 'test_accuracy', 'test_f1', 'cv_accuracy_mean']].sort_values('test_accuracy', ascending=False))\n",
    "else:\n",
    "    print(\"Nenhum dado dispon√≠vel para treinamento!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df) > 0 and results:\n",
    "    # Seleciona melhor modelo\n",
    "    best_model_name = max(results.keys(), key=lambda k: results[k]['metrics']['test_accuracy'])\n",
    "    best_model = results[best_model_name]\n",
    "    \n",
    "    print(f\"Melhor modelo: {best_model_name}\")\n",
    "    print(f\"Accuracy: {best_model['metrics']['test_accuracy']:.4f}\")\n",
    "    \n",
    "    # Matriz de confus√£o\n",
    "    cm = confusion_matrix(y_test, best_model['predictions'])\n",
    "    \n",
    "    # Visualiza√ß√£o\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f'Matriz de Confus√£o - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Classe Real', fontsize=12)\n",
    "    plt.xlabel('Classe Predita', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Relat√≥rio de classifica√ß√£o\n",
    "    print(\"\\nRelat√≥rio de Classifica√ß√£o:\")\n",
    "    print(classification_report(y_test, best_model['predictions'], target_names=le.classes_))\n",
    "else:\n",
    "    print(\"Nenhum modelo treinado dispon√≠vel!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resumo Final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RESUMO DA MODELAGEM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(df) > 0 and results:\n",
    "    print(f\"\\nModelos treinados: {len(results)}\")\n",
    "    print(f\"Total de registros: {len(df):,}\")\n",
    "    print(f\"Features utilizadas: {len(feature_cols)}\")\n",
    "    \n",
    "    print(f\"\\nAcesse o MLFlow em: http://localhost:5000\")\n",
    "    print(f\"   Experimento: intensidade_chuva_classificacao\")\n",
    "    \n",
    "    print(f\"\\nPr√≥ximos passos:\")\n",
    "    print(f\"   1. Analisar resultados no MLFlow\")\n",
    "    print(f\"   2. Executar notebook 04_preparacao_visualizacao.ipynb\")\n",
    "    print(f\"   3. Criar dashboards no Grafana (http://localhost:3000)\")\n",
    "else:\n",
    "    print(\"\\nExecute primeiro os notebooks anteriores!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
